<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[CPU | 指令 - 编译器优化]]></title>
      <url>/cpu/2020/11/19/cpu-2-instruction-complier-optimize/</url>
      <content type="text"><![CDATA[一段代码想要最终被计算机执行，首先需要被翻译成机器可识别和执行的指令。在这个过程中，有两个重要的角色，编译器 和 指令集。代码编译的过程往往包含几个步骤：代码 -&gt; 词法语法分析 -&gt; 语义分析 -&gt; 中间代码生成 -&gt; 目标代码生成在这个过程中，（1）、（2）依赖于上层的编程语言设计（3）会将分析结果编译成中间代码。在这个阶段，编译器会尝试对中间代码进行优化，通过减少无效或冗余的代码、计算强度优化等手段，以助于减少最终生成的指令数，或使用更高效的指令（4）基于中间代码生成机器可执行的目标代码，这个过程和操作系统、指令集、内存等相关。其中，不同的指令集也会带来不同的效率。编译器优化以 gcc 为例，我们来简单了解一下编译器优化。gcc 编译器会在编译速度、生成代码大小和生成代码执行速度三个方面尝试进行优化。在默认情况下，gcc 编译器不开启编译优化，因为编译器的目标是减少编译时间、保证编译结果能够按照期望进行测试。Without any optimization option, the compiler's goal is to reduce the cost of compilation and to make debugging produce the expected results.  Statements are independent: if you stop the program with a breakpoint between statements, you can then assign a new value to any variable or change the program counter to any other statement in the function and get exactly the results you expect from the source code.编译优化我们以一个简单的例子，来简单了解一下编译优化，看看编译器可能会做哪些事情。#include &lt;stdlib.h&gt;void main() {        int loop = 1000000000;        long sum = 0;        int index = 1;        printf("%d", index + 6);}这是一段 C 语言代码，代码做了变量声明和打印，先来看看不开启编译优化的情况下，编译出来的汇编语言结果：.LC0:        .string "%d"main:        pushq   %rbp    #        movq    %rsp, %rbp      #,        subq    $16, %rsp       #,        movl    $1000000000, -16(%rbp)  #, loop        movq    $0, -8(%rbp)    #, sum        movl    $1, -12(%rbp)   #, index        movl    -12(%rbp), %eax # index, tmp60        addl    $6, %eax        #, D.2418        movl    %eax, %esi      # D.2418,        movl    $.LC0, %edi     #,        movl    $0, %eax        #,        call    printf  #        ret通过 gcc -S -fverbose-asm，我们可以获得添加了变量备注的汇编结果。从中可以粗略看到各个变量的创建，通过 addl 进行了 index + 6 的操作，并最终通过 call调用 printf 方法。如果我们开启编译优化，则得到的结果会有很大不同：.LC0:        .string "%d"main:        movl    $7, %esi        #,        movl    $.LC0, %edi     #,        xorl    %eax, %eax      #        jmp     printf  #最直观的感受是指令少了更多，更加精简了，细看之下，会发现有一些改变：（1）消除了冗余的声明里面一些声明了，但是没有使用到的变量，最终被移除了。比如sum、loop、index（2）编译期间能够进行的计算提前做在代码中，index变量是参与运算，但是在最终的指令中也被移除了，而这个过程被提前进行了计算，index = 6，那么 index + 1可以提前预知判断为7，则在编译阶段直接进行了替换。在指令上，实际是将： movl    $1, -12(%rbp)   #, index movl    -12(%rbp), %eax # index, tmp60 addl    $6, %eax        #, D.2418 movl    %eax, %esi      # D.2418,变为了： movl    $7, %esi精简了编译出的指令结果。（3）指令优化在编译优化前的指令里，函数执行的最后可以看到这样一段指令： movl    $0, %eax        它的目的只将累加器归0，而在开启编译后话后，变成了这样： xorl    %eax, %eax      为什么会有这样的变化呢？我们可以简单对比一下这两个命令。我们使用GNU 汇编器as，分别对这两段指令进行编译，并通过 objdump -D 来看看两个命令编译后的结果： 0:	b8 00 00 00 00       	mov    $0x0,%eax 0:	31 c0                	xor    %eax,%eax可以发现，mov 指令占用大小是 xor的 2.5 倍，从大小上来看，xor更胜一筹。可以看出，编译优化会对指令进行优化，选择成本代价更低的指令，生成代码的大小也是编译优化中考虑的一部分。编译优化项从上面的例子可以看到，编译器会从不同的角度进行指令优化，在 gcc 的编译优化选项中，我们选取其中的一部分来看看：-fmove-loop-invariants      Move loop invariant computations out of loops-funroll-loops              Perform loop unrolling when iteration count is known-finline-functions          Integrate functions not declared "inline" into their callers when profitable-fshort-double              Use the same size for double as for float-fjump-tables               Use jump tables for sufficiently large switch statements-fno-threadsafe-statics     Do not generate thread-safe code for initializing local statics以-finline-functions为例，该优化项会尝试将非inline函数进行内联，对下面的代码进行优化：#include &lt;stdlib.h&gt;#include &lt;time.h&gt;int add(int a, int b) {        return a + b;}void main(int argc, char* argv[]) {        printf("%d \n", add(atoi(argv[1]), atoi(argv[2])));}代码读取main函数参数的两个参数，转化为整数猴进行想加，来看看它优化前的中间代码：add:        pushq   %rbp    #        movq    %rsp, %rbp      #        movl    %edi, -4(%rbp)  # a, a        movl    %esi, -8(%rbp)  # b, b        movl    -8(%rbp), %eax  # b, tmp61        movl    -4(%rbp), %edx  # a, tmp62        addl    %edx, %eax      # tmp62, D.2430        popq    %rbp    #        retmain:		  ......        movl    %ebx, %esi      # b -&gt; esi        movl    %eax, %edi      # a -&gt; edi        call    add     #        movl    %eax, %esi      # D.2433,        movl    $.LC0, %edi     #,        movl    $0, %eax        #,        call    printf  #        ......从main函数中可以看到，先调用了call add进行加法，再调用call printf输出。当我们开启编译优化，并开启函数内联优化，再来看看编译结果：add:        leal    (%rdi,%rsi), %eax                retmain:		  ......        leal    0(%rbp,%rax), %esi     # a,b值已放入rbp、rax        movl    $.LC0, %edi             call    printf  #        ......通过gcc -O -finline-functions开启函数内联优化进行编译，结果发生了变化：（1）add函数的指令得到精简和优化，原因是参数-O实际上是开启了-O1级优化，该级别优化不包含-finline-functions，所以手动开启了函数内联优化（2）main函数中已经没有了call add，而是将add函数进行内联处理，将leal指令放在了main函数中编译优化等级在上面的优化中，我们有说到一个概念，编译优化等级。gcc 将编译优化项进行了分类，划分了出多个优化等级用于不同的场景。            优化等级      说明                  -O0      默认优化等级，即不开启编译优化，只尝试减少编译时间              -O/-O1      尝试减少代码大小，缩短代码执行时间，不会执行需要消耗大量编译时间的优化。对于大函数的编译优化会占用更多的时间和内存。              -O2      与-O1类似，会提升编译时间和代码性能，几乎开启除了时空权衡优化外的所有优化项              -O3      在-O2级别的基础上，开启了更多的优化项，最高优化等级，以编译时间、代码大小、内存为代价获取更高的性能。在部分情况下可能会降低性能。              -Os      优化代码大小，会开启-O2中不会增加代码大小的优化项              -Ofast      开启-O3所有优化项，该优化等级不会严格遵循语言标准      对代码性能的影响编译优化对最终的代码性能有什么影响呢，来看一个例子：#include &lt;stdlib.h&gt;#include &lt;time.h&gt;void main() {        int loop = 1000000000;        long sum = 0;        int start_time = clock();        int index = 0;        for (index = 0; index &lt; loop; index ++) {                sum += index;        }        int end_time = clock();        printf("Sum : %ld, Time Cost : %lf \n", sum, (end_time - start_time) * 1.0 / CLOCKS_PER_SEC);}依旧是一个循环加的例子，并记录加法运算时间。在不开启编译优化的情况下，执行时间如下：开启-O3级优化后，执行时间如下：优化后，执行时间只有原来的10%左右，效果明显。（但是这个例子算是一个特殊的例子，计算过程可以用上向量化计算指令，实现并行计算，才能达到这么明显的效果，其他场景下不一定）优化有风险编译器优化这么厉害，当然也有“副作用”，来看看下面的例子：#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;int f() {        int i;        int j = 0;        for ( i = 1; i &gt; 0; i += i) {                ++j;        }        return j;}void main() {        int ret = f();        printf("%d\n", ret);}函数中的for里，依赖于i来判断是否结束。正常判断下，i循环加溢出后变成负数，就会终止循环，结果如下：但是当我们开启-O2优化后，会进入死循环：我们来看看优化前后的汇编指令：优化前 main：		  ......        movl    $1, -8(%rbp)    #, i        jmp     .L2     #.L3:        addl    $1, -4(%rbp)    #, j        movl    -8(%rbp), %eax  # i, tmp64        addl    %eax, %eax      # tmp64, tmp63        movl    %eax, -8(%rbp)  # tmp63, i.L2:        cmpl    $0, -8(%rbp)    #, i        jg      .L3     #,		  ......优化后 main：     	  .......L2:        jmp     .L2     		  ......在编译优化后，变成了死循环。这是一个特殊的现象，在这个过程中，有符号证书越界（Signed Integer Overflow）在 C99 标准中是一个未定义行为，该行为对应的实现可能是隐式转换或者异常等。在 gcc 中，编译器会 overflow 不会发生，将这段代码编译为死循环。（可能还会有类似的情况，具体可以参考CERT - Dangerous Optimizations and the Loss of Causality）选择性编译优化既然危险系数这么高，就放弃不用吗，当然不行，我们可以选择对部分代码进行编译优化：#pragma GCC optimize ("O3")该语句会对其之后的代码开启对应级别的编译变化，语句之前的代码不影响，举个栗子：#include &lt;stdlib.h&gt;#include &lt;time.h&gt;int f();void main() {        int loop = 1000000000;        long sum = 0;        int index = 1;        int ret = f();        printf("%d \n", index + 6);        printf("%d \n", ret);}# pragma GCC optimize("O3")int f() {        int i;        int j = 0;        for ( i = 1; i &gt; 0; i += i) {                ++j;        }        return j;}在gcc编译时不开启编译优化，得到编译后的汇编指令：main:        ......        movl    $1000000000, -20(%rbp)  #, loop        movq    $0, -8(%rbp)    #, sum        movl    $1, -16(%rbp)   #, index        movl    $0, %eax        #,        call    f       #        movl    %eax, -12(%rbp) # tmp60, ret        movl    -16(%rbp), %eax # index, tmp61        addl    $6, %eax        #, D.2431        movl    %eax, %esi      # D.2431,        movl    $.LC0, %edi     #,        movl    $0, %eax        #,        call    printf  #        movl    -12(%rbp), %eax # ret, tmp62        movl    %eax, %esi      # tmp62,        movl    $.LC0, %edi     #,        movl    $0, %eax        #,        call    printf  #        retf:        pushq   %rbp    #        movq    %rsp, %rbp      #.L3:        jmp     .L3     #此时在main函数阶段是正常编译的，在#pragma GCC optimize之后的f函数将会开启编译优化，编译成死循环]]></content>
      <categories>
        
          <category> CPU </category>
        
      </categories>
      <tags>
        
          <tag> CPU </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[CPU | 主频]]></title>
      <url>/cpu/2020/11/12/cpu-1-freq/</url>
      <content type="text"><![CDATA[以 Intel 的 i7 - 8700 为例，我们来看看 CPU 的主频。如何理解主频CPU主频越高，单核性能越强，CPU的运算速度更快。应该如何理解？程序执行时间 ≈ 程序指令数 * 指令平均时钟周期（CPI） * 单个时钟周期时间其中在程序代码确定的情况下，即 程序指令数 * 指令平均时钟周期（CPI）得到的时钟周期总数固定，则单个时钟周期时间决定程序的执行时间，而主频决定了单个时钟周期的时间。主频 = 1s / 时钟周期时间举个栗子，假设CPU在一个时钟周期执行一条运算指令，CPU 1GHz 和 2GHz，意味着1ns和0.5ns执行1条运算指令，0.5ns相比于1ns快了一倍，自然运算速度也更快。（但是实际上更复杂一些，指令周期包含取指令、执行指令，一个指令周期由若干个机器周期组成，机器周期由多个时钟周期组成）CPU是以主频稳定运行的吗要解释这个问题，先来看看CPU频率是怎么定义的。处理器基本频率表示处理器晶体管打开和关闭的速率。处理器基本频率是 TDP 定义的操作点。频率以千兆赫兹 (GHz) 或每秒十亿次循环计。以 Intel 的 CPU 为例，官方给出的CPU频率为基础频率，是 TDP 定义的操作点。说简单点，即CPU在TDP功耗下，能长时间稳定运行的最大频率（注意，并不是指CPU最多只能跑到这个最大频率，后面我们会讲到）。想要查看到实际CPU的频率，可以通过/proc/cpuinfo查看每个核心的信息，可以看到核心的频率是在不断变化的：grep -E 'cpu MHz|processor' /proc/cpuinfo为什么CPU实际频率会超过基础频率从上图中可以发现，i7-8700 的基础频率是 3.2 GHz，而实际的核心频率已经达到 4.4 GHz 左右，超过了基础频率，原因是 Intel 的 Trubo Boost 睿频加速技术（AMD 也有类似的技术，Trubo Core），根据需要动态调节处理器频率，允许CPU在一段时间内超越它的基础频率， i7 - 8700的最大睿频频率可以达到4.6 GHz。现代 Intel CPU 基本都支持睿频，并自动开启，同时也是可以通过配置开启或关闭的，echo 1 &gt; /sys/devices/system/cpu/intel_pstate/no_trubo默认为0，表示开启睿频，配置为1则关闭睿频，关闭后，CPU频率稳定在 3.2 GHz左右（超频也可以让 CPU 实际频率超过基础频率，需要 CPU 和主板支持）除了CPU的频率可以调整吗答案当然是肯定的，为了实现CPU调频，Linux 内核提供了 cpufreq 子模块来完成这一目的。cpufreq 子模块该模块包含四个部分：Core Framework 核心框架、Scaling Governor 调频器、Scaling Driver 调频驱动、Scaling Policy 调频策略，它们之间的关系如下：(1) 核心框架，提供通用的代码框架和接口来支持CPU调频linux/include/cpufreq.h 中定义了数据结构和接口来(2) 调频器，实现了不同的算法来评估所需的CPU频率struct cpufreq_governor {	char       name[CPUFREQ_NAME_LEN];	int        (*init)(struct cpufreq_policy *policy);	void       (*exit)(struct cpufreq_policy *policy);	int        (*start)(struct cpufreq_policy *policy);	void       (*stop)(struct cpufreq_policy *policy);	void       (*limits)(struct cpufreq_policy *policy);	ssize_t    (*show_setspeed)	(struct cpufreq_policy *policy, char *buf);	int        (*store_setspeed)	(struct cpufreq_policy *policy, unsigned int freq);	bool               dynamic_switching;	struct list_head   governor_list;	struct module      *owner;};代码展示了调频器设计的核心数据结构和方法，方法均为函数指针，不同的调频器可以自由定义实现(3) 调频驱动，与硬件直接通信，获取调频器所需要的效能状态，提供接口进行调整struct cpufreq_driver {  char      name[CPUFREQ_NAME_LEN];  u8		flags;  void		*driver_data;  int		(*init)(struct cpufreq_policy *policy);  int		(*verify)(struct cpufreq_policy_data *policy);  int		(*setpolicy)(struct cpufreq_policy *policy);  int		(*online)(struct cpufreq_policy *policy);  int		(*offline)(struct cpufreq_policy *policy);  int		(*exit)(struct cpufreq_policy *policy);  void      (*stop_cpu)(struct cpufreq_policy *policy);  int		(*suspend)(struct cpufreq_policy *policy);  int		(*resume)(struct cpufreq_policy *policy);  void      (*ready)(struct cpufreq_policy *policy);  ...};在配置中，cpufreq 提供了一些通用的调频器，不同的调频器提供了功能不同的调频算法，用于不同的场合。performance    会在 scaling_max_freq 限制的范围内，尽可能进入高频率状态powersave会在 scaling_min_freq 限制的范围内，尽可能进入低频率状态userspace该调频器不做任何配置，允许通过 scaling_setspeed 自定义 CPU 频率ondemand定时基于 CPU 负载进行频率动态设置的方式，负载低时降频，负载高时升频（系统在忙和闲之间切换频繁时效果并不好）conservative与 ondemand 类似，定时基于 CPU 负载进行调频，不同在于频率调整采用逐步递变的方式。schedutil基于 CPU 使用率，利用内核机制 - utilization update callback， 通过负载变化回调机制来进行调频的方法（相比于 ondemand 和 conservative 的定时获取，能更快获取 CPU 负载变化进行调整）(4) 每个 CPU 核心独有一份调频策略，保存有当前 CPU 频率状态、调频器、调频驱动和策略配置等struct cpufreq_policy {	cpumask_var_t		cpus;	/* Online CPUs only */	cpumask_var_t		related_cpus; /* Online + Offline CPUs */	cpumask_var_t		real_cpus; /* Related and present */	unsigned int		cpu;    /* cpu managing this policy, must be online */	struct             cpufreq_cpuinfo	cpuinfo;/* current cpu info */	unsigned int		min;    /* min freq in kHz */	unsigned int		max;    /* max freq in kHz */	unsigned int		cur;    /* cur freq in kHz, only needed if cpufreq governors are used */	unsigned int		policy; /* see above */	unsigned int		last_policy; /* policy before unplug */	struct             cpufreq_governor	*governor; /* see below */	void			    *governor_data; /* scaling governor */	char			    last_governor[CPUFREQ_NAME_LEN]; /* last governor used */	struct             cpufreq_stats	*stats;	void			    *driver_data; /* scaling driver */	.....};在了解 cpufreq 的结构后，我们来看看如何调整 CPU 频率。(1) 使用 cpufreq_policy 来调整 CPU 频率在内核初始化时，cpufreq 会创建 sysfs 目录来展示 cpufreq_policy 调频策略中的部分信息，ls /sys/devices/system/cpu/cpufreq/policy{X}其中，{X} 对应 CPU 核心的编号，每一个 CPU 核心都是独立的调频策略。（对应核心的 policy 也链接到了/sys/devices/system/cpu/cpu{X}/cpufreq）调整策略也包含一些通用的属性，cpuinfo_* 记录的是CPU硬件支持的频率信息，scaling_* 表示通过 cpufreq 进行扩展调节的所支持频率、配置等信息。（数据定义对应 cqufreq.h 中的 cpufreq_policy ）cpuinfo_min_freq、cpuinfo_max_freqCPU支持的最小、最大频率cpuinfo_cur_freq从硬件读取到的CPU当前实际频率。如果这个值不确定的话，可能不会展示。（我测试的时候是没有的）cpuinfo_transition_latency采用 policy 进行效能状态转换所花费的时间（ns）affected_cpus属于当前 policy 的 online cpurelated_cpus属于当前 policy 的 所有 cpu，包含 online 和 offlinescaling_available_governors当前内核提供的可用调频器或驱动提供调频算法scaling_cur_freq最后一次通过调频驱动获得的 CPU 频率，而非当前时刻的频率。scaling_driver当前使用的调频驱动scaling_governor当前 policy 使用的调频器或调频算法，该值可修改scaling_min_freq、scaling_max_freq当前 policy 允许的最小、最大频率，该值可修改（kHz）scaling_setspeed当使用 userspace 调频器时可用，可配置 cpu 频率（kHz）通过 scaling_setspeed，我们可以对CPU频率进行设置，但是其受限于调频器，只有 userspace 才可以进行 CPU 频率自定义。这是在我本地查看0号核心的输出结果，当前核心频率944 MHz，在频率范围上与i7 - 8700 的官方定义一致，调频器使用的 powersave，调频驱动使用的是intel_psate，在使用 powersave 调频器的情况下，scaling_setspeed 处于 unsupported 状态，而支持的调速器也不包含 userspace。这种情况下，需要通过其他方式来进行频率调整。(2) 使用 cpufreq_driver 来调整 CPU 频率在 Linux 内核源码中，intel_pstate.c 记录了其内部实现。既然是调频驱动，则必须实现 cpufreq 定义的接口，intel_pstate 定义的接口实现如下：static struct cpufreq_driver intel_pstate = {	.flags		= CPUFREQ_CONST_LOOPS,	.verify		= intel_pstate_verify_policy,	.setpolicy	= intel_pstate_set_policy,	.suspend	= intel_pstate_suspend,	.resume		= intel_pstate_resume,	.init		= intel_pstate_cpu_init,	.exit		= intel_pstate_cpu_exit,	.stop_cpu	= intel_pstate_stop_cpu,	.offline	= intel_pstate_cpu_offline,	.online		= intel_pstate_cpu_online,	.update_limits	= intel_pstate_update_limits,	.name		= "intel_pstate",};在 intel_pstate_set_policy 中，会设置生效调频策略，并通过 intel_pstate_update_perf_limits 更新 CPU 能耗配置int max_freq = intel_pstate_get_max_freq(cpu);static int intel_pstate_get_max_freq(struct cpudata *cpu){	return global.turbo_disabled || global.no_turbo ?			cpu-&gt;pstate.max_freq : cpu-&gt;pstate.turbo_freq;}其中，max_freq 取决于是否开启睿频，未开启则取默认的最大频率，即基础频率；已开启则使用睿频频率。通过睿频可以提升 CPU 频率上限，也符合我们之前实验的结果。可是由此看来，好像没有其他方式来修改 CPU 的频率。细看代码，通过 intel_pstate_update_perf_limits 的实现，可以发现CPU 的实际性能表现并不仅仅是通过 max_freq 决定的，还涉及一个参数 max_policy_perf，用于设定 CPU 的最大性能比例。global_max = DIV_ROUND_UP(turbo_max * global.max_perf_pct, 100);cpu-&gt;max_perf_ratio = min(max_policy_perf, global_max);cpu-&gt;max_perf_ratio = max(min_policy_perf, cpu-&gt;max_perf_ratio);通过 intel_pstate 提供的配置入口可以进行修改/sys/devices/system/cpu/intel_pstate/max_perf_pct（值范围[0, 100]）该值实际是设置最大的性能百分比，max_perf_pct = 50 可以限制其主频最多跑到 max_freq 的 50%。CPU 频率对我们的程序有什么影响来做个简单的测试，代码如下：func main() {	loop := uint64(150000000000)	sum := uint64(0)	startTime := time.Now().UnixNano()	for index := uint64(0); index &lt; loop; index++ {		sum += index	}	endTime := time.Now().UnixNano()	fmt.Println("Time cost in mills : ", (endTime - startTime) / 1000000)}代码逻辑很简单，做循环加法，纯 CPU 运算，最后计算耗时（nano）。在不 桶的CPU 频率配置下，我们来看看结果：            核心频率      核心使用率      计算耗时(ms)                  4.57 GHz      100%      33581              3.2 GHz      100%      47130              2.0 GHz      100%      71848      随着主频下降，计算耗时逐渐上升，且主频下降的比例与计算耗时的增长比例相近。主频决定了 CPU 的运算速度，因此当主频降低时，计算耗时也相应增加。CPU 频率和使用率之间的关系这一点上往往容易产生误区，会觉得主频越高，使用率一定高，或者使用率越高，主频也一定高。实际上，两者的关系有点像水管和水流的关系，CPU频率类似水管大小，使用率是水流，水管可以很大，水流可以很小。还是上面的例子，只是在每次循环加之后，增加一个sleep：func main() {	loop := uint64(150000000000)	sum := uint64(0)	startTime := time.Now().UnixNano()	for index := uint64(0); index &lt; loop; index++ {		sum += index		time.Sleep(100)	}	endTime := time.Now().UnixNano()	fmt.Println("Time cost in mills : ", (endTime - startTime) / 1000000)}因为每次循环计算都会sleep，所以 CPU 实际跑不满的：本地测试CPU使用率在60%左右，而主频已经达到了4.3 GHz左右的睿频频率，此时相当于水管很大，但是水流只占水管大小的60%左右。如果我们对 CPU 进行降频，把频率将至3.2GHz左右，相同搞定代码下，结果则会不一样：此时同样的运算在降频后，CPU 使用率达到了100%，相当于使用了更小的水管后，水流跑满了整个水管。]]></content>
      <categories>
        
          <category> CPU </category>
        
      </categories>
      <tags>
        
          <tag> CPU </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[CPU | 命名]]></title>
      <url>/cpu/2020/11/10/cpu-0-name-meaning/</url>
      <content type="text"><![CDATA[我们日常总会看到各种各样的CPU，苹果的A12、A13，Intel 的 i3、i5、i7等，同时还会带上一系列的后缀，比如 A10X、i9 - 9880H，不同的后缀具有不同的含义。苹果A系列处理器Apple - Brand 品牌、商标A - 产品型号12 - 产品代，第十二代产品X - 型号，同代中区分不同配置、参数的产品。A12Z 比 A12 增加了两个高性能大核心；A12X 相比于 A12Z ，开启了第八颗GPU核心。Bionic - 后缀。从A10开始，CPU名字后面会加入一个单词。A10 Fusion（融合），融合表示首次使用大小核融合；A11 Bionic（仿生），代表集成了神经网络引擎，为机器学习所需的高速运算提供支持，例如FaceID、AR等。Intel Core i 系列处理器Intel Core - Brand，品牌、商标i7 - Brand Modifier，产品型号9 - Generation 产品代，第九代产品980 - SKU Numeric Digits，SKU编号，一般越大代表性能约强劲HK - Product Line Suffix，又称 SKU Suffix，SKU 后缀，描述处理器能力。例如，H代表搭载高性能集成显卡；K代表未锁可超频等等Intel Xeon 系列处理器和 Intel Core 处理器家族的命名类似，日常用的不多，不作详细说明。（可参考What Do Intel® Processor Numbers Mean?）该系列属于服务器级别的处理器，在云计算、实时分析、大数据处理、工业设计等相关行业会有用到，拥有更高的效率和稳定性。处理器家族区分出三大类别，E系列、D系列和W系列，E系列为入门级服务器解决方案，D系列针对空间和电源受限的环境提供了负载优化，W系列为最高级别的终极处理平台。AMD Ryzen 系列处理器Ryzen  - Brand，品牌、商标7 - Segment，段号，段号越大性能越好1 - Generation 产品代，第1代产品7 - Performance Level，性能分级，分级越大性能越高00 - Model Number，型号，类似SKU NumberX - Power Suffix，后缀，描述处理器能力。]]></content>
      <categories>
        
          <category> CPU </category>
        
      </categories>
      <tags>
        
          <tag> CPU </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Kotlin升级导致的when异常问题]]></title>
      <url>/kotlin/2019/02/11/kotlin-when/</url>
      <content type="text"><![CDATA[送测结束，开心上线，结果线上突然报错，发现代码走到了一个理论上不可能走到的分支里，又遇到鬼故事了_(:з」∠)_ GG。问题背景一段神奇的代码：两个枚举类，分别定义如下：EnumA ↓enum class EnumA(var value: Int) {    A_1(1),    A_2(2)}FakeEnumA ↓enum class FakeEnumA(var value: Int) {    A_1(1),    A_2(2)}代码里进行了一段神奇的操作：val enumA = EnumA.A_1when (enumA) {    FakeEnumA.A_1 -&gt; println("I'm A_1")    FakeEnumA.A_2 -&gt; println("I'm A_2")    else -&gt; println("else")}代码正常编译，理论上来说，不同类型比较，应该进入else，而结果确实进入了else。但是。。这个版本之前，代码执行，输出了“I’m A_1”。。而在新版本发布后，代码执行， 输出了“else”。。可以确定的是这段代码相关内容没有任何改动，那么为什么会出现两种不同的结果呢？异常现象两个不同的类对象比较，理论上比较肯定会不同，但是原代码比较判定为相等问题分析咋办。。既然代码没有变过，那么项目有没有其他变更呢？有的，我们把Kotlin升级了，从1.2升级到了1.3，因为1.3提供了协程。。贼开心。。抱着算一把命的想法，把变更回滚，Kotlin改回1.2，发现果然复现了原来异常的情况，两个不同的类对象，比较判定为了相等，输出了”I’m A_1”,那么基本可以确定是由于Kotlin升级导致的结果。那么为什么旧版本Kotlin会产生这种现象呢？Kotlin代码最终也是编译生成字节码跑在JVM上的，那么来看看字节码吧~Kotlin1.2的字节码实现先看看Kotlin 1.2的时候，这段代码的字节码是怎样的 ↓Code:   0: aload_0   1: ldc           #9                  // String args   3: invokestatic  #15                 // Method kotlin/jvm/internal/Intrinsics.checkParameterIsNotNull:(Ljava/lang/Object;Ljava/lang/String;)V   6: getstatic     #21                 // Field com/seewo/share/example/when/EnumA.A_1:Lcom/seewo/share/example/when/EnumA;   9: astore_1                            10: aload_1  12: getstatic     #27                 // Field com/seewo/share/example/when/EnumTestMainKt$WhenMappings.$EnumSwitchMapping$0:[I  14: swap  15: invokevirtual #31                 // Method com/seewo/share/example/when/EnumA.ordinal:()I  //取enumA.A_1对应的oridinal()  18: iaload  19: tableswitch   { // 1 to 2         // 通过tableswitch，实现对应代码when(enumA)                 1: 40                                   2: 53                             default: 66                        }  40: ldc           #33                 // String I'm A_1  42: astore_2  43: getstatic     #39                 // Field java/lang/System.out:Ljava/io/PrintStream;  46: aload_2  47: invokevirtual #45                 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V  50: goto          76  53: ldc           #47                 // String I'm A_2  55: astore_2  56: getstatic     #39                 // Field java/lang/System.out:Ljava/io/PrintStream;  59: aload_2  60: invokevirtual #45                 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V  63: goto          76  66: ldc           #49                 // String else  68: astore_2  69: getstatic     #39                 // Field java/lang/System.out:Ljava/io/PrintStream;  72: aload_2  73: invokevirtual #45                 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V  76: return}从上面的字节码看，好像并没有啥问题，生成映射、取值、获得映射结果，比较。。比较。。。比。。。较。。。tableswitch。。oridinal。。。oridinal。。。oridinal不是返回的枚举中类型序号吗。。。所以这个比较只是在比较序号的吗。。。EnumA和FakeEnumA中枚举类型声明的顺序确实是一样的，那如果我把FakeEnumA中的定义顺序换一下，不就正常了吗。。然后我测试了一把，发现并没有用，结果依然是判定相等，那这是为什么呢。。。Kotlin 1.2 中，when的实现继续看字节码，发现通过iaload加载了EnumTestMainKt$WhenMappings.$EnumSwitchMapping$中index为0(A.A_1.oridnal)的元素，进入tableswitch进行跳转，那么这个EnumSwitchMapping又是什么呢？继续看字节码:public final class com.seewo.share.example.when.EnumTestMainKt$WhenMappings {  public static final int[] $EnumSwitchMapping$0;  static {};    Code:       0: invokestatic  #14                 // Method com/seewo/share/example/when/EnumA.values:()[Lcom/seewo/share/example/when/EnumA;       3: arraylength       4: newarray       int       6: putstatic     #16                 // Field $EnumSwitchMapping$0:[I       9: getstatic     #16                 // Field $EnumSwitchMapping$0:[I      12: getstatic     #20                 // Field com/seewo/share/example/when/EnumA.A_1:Lcom/seewo/share/example/when/EnumA;      15: invokevirtual #24                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      18: iconst_1      19: iastore      20: getstatic     #16                 // Field $EnumSwitchMapping$0:[I      23: getstatic     #27                 // Field com/seewo/share/example/when/EnumA.A_2:Lcom/seewo/share/example/when/EnumA;      26: invokevirtual #24                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      29: iconst_2      30: iastore      31: return}该Mapping中，基于EnumA中的元素个数，创建了一个数组，数组中的对应关系是怎样的呢，我们按照字节码一步步来看:9         -&gt; getstatic，获取到Mapping中的数组元素12~15     -&gt; EnumA.A_1.ordinal()，获取到018        -&gt; iconst_1，得到整数119        -&gt; iastore，存入数组在iastore前，操作数栈中的元素如下:                    1                    ordinal                    $EnumSwitchMapping$0            而iastore命令调用的栈描述如下：                    value                    index                    arrayref            可以得出其等同于语句$EnumSwitchMapping$0[ordinal]=index则该Mapping中数组的对应关系为：mapping[0]=1, mapping[1]=2，可以看出，该Mapping实际保存了枚举类型ordinal到tableswitch的映射关系那么再看回之前的iaload，通过EnumA.A_1的ordinal，从Mapping中加载出的值为1，对应到tableswitch，跳转到40，最终进入”I’m A_1”分支所以总结下来，跳转过程如下：那么整个过程看来，和FakeEnumA没有一点关系，那么真的是这样吗？EnumSwitchMapping在Kotlin 1.2编译生成的字节码中，EnumSwitchMapping主要保存了ordinal到tableswitch的映射关系，字节码如下：public final class com.seewo.share.example.when.EnumTestMainKt$WhenMappings {  public static final int[] $EnumSwitchMapping$0;  static {};    Code:       0: invokestatic  #14                 // Method com/seewo/share/example/when/EnumA.values:()[Lcom/seewo/share/example/when/EnumA;       3: arraylength       4: newarray       int       6: putstatic     #16                 // Field $EnumSwitchMapping$0:[I       9: getstatic     #16                 // Field $EnumSwitchMapping$0:[I      12: getstatic     #20                 // Field com/seewo/share/example/when/EnumA.A_1:Lcom/seewo/share/example/when/EnumA;      15: invokevirtual #24                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      18: iconst_1      19: iastore      20: getstatic     #16                 // Field $EnumSwitchMapping$0:[I      23: getstatic     #27                 // Field com/seewo/share/example/when/EnumA.A_2:Lcom/seewo/share/example/when/EnumA;      26: invokevirtual #24                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      29: iconst_2      30: iastore      31: return}可以看出整个Mapping的生成似乎和FakeEnumA没有任何关系，但是实际上是这样的吗？我们尝试改动FakeEnumA和when的代码，进行如下测试： 1.FakeEnumA添加一个新的类型A_3，代码如下：enum class FakeEnumA(var value: Int) {    A_1(1),    A_2(2),    A_3(3)} 2.when跳转中，把FakeEnumA.A_1改为FakeEnumA.A_3，代码如下：when (enumA) {    FakeEnumA.A_3 -&gt; println("I'm A_1")    FakeEnumA.A_2 -&gt; println("I'm A_2")    else -&gt; println("else")}以上代码均正常编译通过，如果整个过程和FakeEnumA没有关系的话，那么应该会正常运行，并输出”I’m A_1”。但是实际执行却抛出异常：Exception in thread "main" java.lang.NoSuchFieldError: A_3        at com.share.example.when.EnumTestMainKt$WhenMappings.&lt;clinit&gt;(Unknown Source)        at com.share.example.when.EnumTestMainKt.main(EnumTestMain.kt:17)在运行时抛出了NoSuchFieldError,说明在编译的时候时候，编译器校验正常通过，但在运行的时候，发现A_3找不到了，抛出异常。此时的EnumSwitchMapping字节码如下：public final class com.seewo.share.example.when.EnumTestMainKt$WhenMappings {  public static final int[] $EnumSwitchMapping$0;  static {};    Code:       0: invokestatic  #14                 // Method com/seewo/share/example/when/EnumA.values:()[Lcom/seewo/share/example/when/EnumA;       3: arraylength       4: newarray       int       6: putstatic     #16                 // Field $EnumSwitchMapping$0:[I       9: getstatic     #16                 // Field $EnumSwitchMapping$0:[I      12: getstatic     #20                 // Field com/seewo/share/example/when/EnumA.A_3:Lcom/seewo/share/example/when/EnumA;      15: invokevirtual #24                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      18: iconst_1      19: iastore      20: getstatic     #16                 // Field $EnumSwitchMapping$0:[I      23: getstatic     #27                 // Field com/seewo/share/example/when/EnumA.A_2:Lcom/seewo/share/example/when/EnumA;      26: invokevirtual #24                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      29: iconst_2      30: iastore      31: return}可以看到，是在类的静态初始化域中，对类内的数组对象进行了初始化，并赋值，其中12: getstatic尝试获取EnumA中的A_3时，发现找不到对应的枚举类型。由此可以推断，该Mapping的在编译时依赖于when中的条件分支（FakeEnumA.A_3和FakeEnumA.A_2）进行生成，而生成时，只取了枚举类型的name，并没有判断是否是同一个枚举类型，最终导致了这个异常。。Kotlin 1.3 中，when的实现综上所述，已经找到了Kotlin 1.2中会进入错误分支的原因，那么为什么Kotlin 1.3中会恢复正常，进入else分支呢？我们看一看使用Kotlin 1.3编译后生成的字节码：public final class com.seewo.share.example.when.EnumTestMainKt {  public static final void main(java.lang.String[]);    Code:       0: aload_0       1: ldc           #9                  // String args       3: invokestatic  #15                 // Method kotlin/jvm/internal/Intrinsics.checkParameterIsNotNull:(Ljava/lang/Object;Ljava/lang/String;)V       6: getstatic     #21                 // Field com/seewo/share/example/when/EnumA.A_1:Lcom/seewo/share/example/when/EnumA;       9: astore_1      10: getstatic     #21                 // Field com/seewo/share/example/when/EnumA.A_1:Lcom/seewo/share/example/when/EnumA;      13: invokevirtual #25                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      16: istore_2      17: getstatic     #31                 // Field java/lang/System.out:Ljava/io/PrintStream;      20: iload_2      21: invokevirtual #37                 // Method java/io/PrintStream.println:(I)V      24: getstatic     #40                 // Field com/seewo/share/example/when/EnumA.A_2:Lcom/seewo/share/example/when/EnumA;      27: invokevirtual #25                 // Method com/seewo/share/example/when/EnumA.ordinal:()I      30: istore_2      31: getstatic     #31                 // Field java/lang/System.out:Ljava/io/PrintStream;      34: iload_2      35: invokevirtual #37                 // Method java/io/PrintStream.println:(I)V      38: getstatic     #45                 // Field com/seewo/share/example/when/FakeEnumA.A_1:Lcom/seewo/share/example/when/FakeEnumA;      41: invokevirtual #46                 // Method com/seewo/share/example/when/FakeEnumA.ordinal:()I      44: istore_2      45: getstatic     #31                 // Field java/lang/System.out:Ljava/io/PrintStream;      48: iload_2      49: invokevirtual #37                 // Method java/io/PrintStream.println:(I)V      52: getstatic     #48                 // Field com/seewo/share/example/when/FakeEnumA.A_2:Lcom/seewo/share/example/when/FakeEnumA;      55: invokevirtual #46                 // Method com/seewo/share/example/when/FakeEnumA.ordinal:()I      58: istore_2      59: getstatic     #31                 // Field java/lang/System.out:Ljava/io/PrintStream;      62: iload_2      63: invokevirtual #37                 // Method java/io/PrintStream.println:(I)V      66: aload_1      67: astore_2      68: aload_2      69: getstatic     #51                 // Field com/seewo/share/example/when/FakeEnumA.A_3:Lcom/seewo/share/example/when/FakeEnumA;      72: if_acmpne     88      75: ldc           #53                 // String I'm A_1      77: astore_3      78: getstatic     #31                 // Field java/lang/System.out:Ljava/io/PrintStream;      81: aload_3      82: invokevirtual #56                 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V      85: goto          118      88: aload_2      89: getstatic     #48                 // Field com/seewo/share/example/when/FakeEnumA.A_2:Lcom/seewo/share/example/when/FakeEnumA;      92: if_acmpne     108      95: ldc           #58                 // String I'm A_2      97: astore_3      98: getstatic     #31                 // Field java/lang/System.out:Ljava/io/PrintStream;     101: aload_3     102: invokevirtual #56                 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V     105: goto          118     108: ldc           #60                 // String else     110: astore_3     111: getstatic     #31                 // Field java/lang/System.out:Ljava/io/PrintStream;     114: aload_3     115: invokevirtual #56                 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V     118: return}首先，生成的字节码中已经没有了EnumSwitchMapping这个类，那么再看看字节码，字节码中也没有了tableswitch，而是使用了if_acmpne进行比较判断。那么if_acmpne是怎么比较的呢 ↓if_acmpne pops the top two object references off the stack and compares them. If the two object references are not equal (i.e. if they refer to different objects), execution branches to the address (pc + branchoffset), where pc is the address of the if_acmpne opcode in the bytecode and branchoffset is a 16-bit signed integer parameter following the if_acmpne opcode in the bytecode. If the object references refer to the same object, execution continues at the next instruction.可以看到，if_acmpne是对两个对象的引用进行比较，如果是两个对象的不相等，则进行跳转。由此可见if_acmpne进行的是对象引用的比较，而EnumA.A_1与FakeEnumA.A_1属于不同的对象，那么72: if_acmpne比较EnumA.A_1与FakeEnumA.A_1，发现两者不相等，跳转至88: aload_2，加载FakeNumA.A_2，与EnumA.A_1进行比较，仍然不相等，最终跳转到108进入else。因此，最终输出了”else”。问题原因（1）Kotlin 1.2 编译实现when语句时，在value为枚举类型的情况下，未进行类型校验，并且使用的Mapping关系映射+tableswitch实现when条件判断和分支跳转；（2）Kotlin 1.2 在编译生成Mapping关系映射生成代码时，仅判断枚举类型name，而两个枚举类中的命名一致，导致Mapping关系映射正常生成，但是错误映射到不相等的分支，最终输出”I’m A_1”；（3）Kotlin 1.3 中，对when的编译实现使用了if_acmpne，进行对象引用比较，代码执行按正常逻辑走入else分支。解决方案调整when比较的条件，使用相同对象进行比较，解决了该问题。]]></content>
      <categories>
        
          <category> Kotlin </category>
        
      </categories>
      <tags>
        
          <tag> Kotlin </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Tomcat类加载NoSuchMethodError异常问题]]></title>
      <url>/jvm/2018/07/14/jvm-classload-priority/</url>
      <content type="text"><![CDATA[最近在开发环境中进行项目部署测试，再次遇一个鬼故事。项目maven打包正常，Tomcat上项目正常启动，但是在调用某个类的特定方法时，出现NoSuchMethodError异常，反编确认对应的JAR包中包含该类和对应的方法，但是JVM依旧报错。异常信息[ERROR] 15:35:43.751 c.c.m.o.e.GlobalExceptionHandler(31) - Handler dispatch failed; nested exception is java.lang.NoSuchMethodError: com.google.common.base.Splitter.splitToList(Ljava/lang/CharSequence;)Ljava/util/List;org.springframework.web.util.NestedServletException: Handler dispatch failed; nested exception is java.lang.NoSuchMethodError: com.google.common.base.Splitter.splitToList(Ljava/lang/CharSequence;)Ljava/util/List;        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:978)        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:897)        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970)        at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:872)        at javax.servlet.http.HttpServlet.service(HttpServlet.java:644)        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846)        at javax.servlet.http.HttpServlet.service(HttpServlet.java:725)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)        at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)        at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99)        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)异常分析项目是在尝试调用Google Guava Splitter中的splitToList方法时，发现该方法未定义。首先，项目编译时正常，所以在此过程中，是能找到对应的类和方法，那么为什么会出现在运行时找不到的情况呢？其次，抛出的异常是NoSuchMethodError，说明ClassLoader成功加载到了对应的类，只是在进行方法调用时，发现方法不存在。针对上面的分析，进行一些猜想的验证： 1.maven打包使用了低版本的Guava，而低版本中没有对应的方法 理论上来说，这种情况不太可能，如果使用了没有对应方法的低版本，那么打包编译是会失败的，实际上反编后，也是可以在对应的类中找到该方法的； 2.JAR冲突，导致使用了低版本的Guava，而低版本中没有对应的方法 然鹅，事实证明不是，maven依赖树中只出现了一个guava包的引用，所以排除这种情况； 3.Tomcat进行Class加载时，加载了低版本的Guava，而低版本中没有对应的方法 于是，我把项目打成了JAR，引入tomcat模块，放到测试环境中运行，一切正常~那么基本可以判断是和服务器Tomcat或JAVA环境有一定的关系，为了弄清楚在加载该类时，是从哪里加载的，在Tomcat启动参数中，加入-XX:+TraceClassLoading -XX:+TraceClassUnloading，用于跟踪Tomcat类加载和卸载，并在日志中进行查看，恩。。。然后发现：恩。。。。。。。恩。。。。。。。。恩。。。。。。。。。嘛玩意儿这是。。。。。根本就是不是从我的JAR包中加载的。。。。从上面的图可以看出，在进行Guava Splitter类加载的时候，从JRE的扩展LIB库中进行了该类的加载，那么为什么没有从项目包中加载，而是从扩展LIB库中进行加载的呢？可以看出，只有在项目部署在服务器Tomcat上的时候，才出现了相应的问题，那么很可能是和服务器中的Tomcat或JAVA环境有关。首先，我们来看一下Tomcat是如何做类加载和管理的。(https://tomcat.apache.org/tomcat-8.0-doc/class-loader-howto.html)Tomcat使用一系列不同的ClassLoader来加载和管理一些基础的常规类，它们是能被所有WEB应用同时使用的，包括JVM的基础运行时类、Tomcat内部类等。而单个应用部署在Tomcat的独立容器中，每个容器中的WEB应用对应的ClassLoader相互隔离，以此来实现隔离。Tomcat中ClassLoader之间是呈现层级关系的，具体结构如下图所示：其中，Bootstrap class loader  用于加载JVM运行时基础类，同时也包含了扩展JAR包目录下的所有类（$JAVA_HOME/jre/lib/ext）；System class loader  一般从CLASSPATH环境变量中进行类初始化，所有的这些对于Tomcat内部类和WEB应用都是可见的。然后，标准的Tomcat启动脚本是会忽略CLASSPATH环境变量，而使用下列仓库进行代替： 1.$CATALINA_HOME/bin/bootstrap.jar  包含用于初始化Tomcat的所需类； 2.$CATALINA_BASE/bin/tomcat-juli.jar or $CATALINA_HOME/bin/tomcat-juli.jar  日志相关的实现类； 3.$CATALINA_HOME/bin/commons-daemon.jar  Apache Commons Daemon 中的类，Linux下可用于实现后台服务，Windows下可用于实现注册为系统服务。Common class loader  包含附加的类，对于Tomcat内部类和所有的WEB应用都是可见的，默认查找CATALINA_HOME和CATALINA_BASE目录下的lib目录；WebappX class loader  为每一个部署在Tomcat中WEB应用实例创建的ClassLoader，包括/WEB-INF/classes下所有解包的类和资源，同时也包含/WEB-INF/lib目录下JAR包中的类和资源。由于前三个ClassLoader是各个WEB应用通用的，当需要加载一个类时，会优先按顺序上最上层ClassLoader进行加载，当一个ClassLoader在对应的目录中没有找到对应的类时，就依次交给下一层级的ClassLoader进行加载。如果最终都没有找到对应的类，则抛出NoClassDefFoundError。综上所述，当尝试进行Google Guava Splitter类的加载时，首先交由Bootstrap class loader进行尝试性的加载，然后在对应目录中的JAR包中进行搜索时，居然从jre/lib/ext目录下的JAR包中找到了对应的类，所以优先进行了加载，而在对该JAR包进行反编后，发现确实包含了Google Guava，并且对应的Guava版本是14.0.1，而在对应的版本下，Guava Splitter确实还没有splitToList方法，所以最终导致类加载成功，但是找不到对应的方法，抛出NoSuchMethodError。异常原因当尝试进行Google Guava Splitter类的加载时，Bootstrap class loader优先找到并加载了低版本的Guava Splitter，而低版本中没有包含splitToList方法。后来在同事里问了一圈，发现是有同事之前测试，将测试JAR包放到了jre/lib/ext目录，导致了该问题的发生。解决方案      经确认后，将该JAR从扩展库目录中移除，处理后恢复正常；        禁止将业务JAR包放到JAVA库目录中，避免相关问题的再次发生；        在对模块进行JAR包封装，或进行SDK开发时，应尽可能较少相关第三方库依赖，避免与引用方依赖发生冲突；        如果无法避免引用第三方常用类库，可以使用maven shade插件，对相关第三方类库的包名进行变更，以此避免相关问题。  ]]></content>
      <categories>
        
          <category> JVM </category>
        
      </categories>
      <tags>
        
          <tag> JVM </tag>
        
          <tag> NoSuchMethodError </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[字符编码]]></title>
      <url>/common/mysql/2018/07/06/character-coding/</url>
      <content type="text"><![CDATA[ 字符、字符集和字符编码                    字符        基本信息单元，字母、数字和标点等                    字符集        字符集合，例如ASCII、GBK                    字符编码        字符集的二进制编码方式            那么问题来了，我们常说的ASCII、GBK等都是指字符编码，为什么被列入字符集里了？实际上对于大部分的字符集来说，一个字符集智慧有一套编码，所以字符集即唯一确定了其编码。但是凡事总有例外，UNICODE字符集就是一个特例，UNICODE存在多种编码方式，包括UTF-8、UTF-16等。常见字符编码ASCII单字节编码字符集，最高位不使用，常设为0.0~31及127为控制码，共33个32~126是字符，共95个空间占用：1字节不够用了怎么办 -&gt; LATIN-1（ISO-8859-1）ASCII扩展字符集，启用最高位。0~127位与ASCII相同，新开启的128~255收录新字符。空间占用：1字节有中文了怎么办 -&gt; GB2312有中文了怎么办？常用中文字符有6000多个~GB2312解决了中文问题，包含常用中文字符0~127位与ASCII相同，高位其他字符取消，采用新规则：当两个大于127的字符连在一起时，就表示一个汉字，前一个为高字节（0xA1到0xF7），后一个为低字节（0xA1到0xFE），可以组合出7000+的汉字。其中，高字节等于字符区号+0xA0，低字节等于字符所在区中的位置+0xA0。同时，GB2312也对一些特殊字符、数字和标点等进行了重新编码，重新编码的这一批字符，就是我们常说的“全角”字符，而127位以下的这些字符就被称为“半角”字符。哎呀，中文那么多不够用啊 -&gt; GBK基于GB2312进行扩展，不再要求低字节一定是127之后的编码，只要第一个字节是大于127的，那么代表这是一个汉字的开始。GBK包含了GB2312的所有内容，同时又增加了近20000个新的汉字。看一个例子：a机智采用GBK编码后，以十六进制方式查看，结果为：61bb fad6 c7第一个字节小于127，和ASCII编码保持一致，可以直接查表得到61对应a；之后一共4个字节，分别对应“机智”，查询后匹配bbfa对应”机“，d6c7对应”智”繁体字  -&gt; BIG5虽然GBK支持少量繁体中文，但是数量有限，于是就出现了BIG5啦。ISO表示我坐不住了 -&gt; UNICODE不同的国家，不同的语言，编码太多，就会出现兼容、转换等问题。这时候，ISO坐不住了。ISO统一了所有语言、字符和数字等编码，创建了UNICODE（Universal Multiple-Octet Coded Character Set），为了能够同时包含大量的字符，UNICODE使用2个字节来统一表示，对于ASCII中低于127位的字符保持不变，其他全部重新编码。前面有提到，UNICODE是字符集，并不能代表字符编码，UNICODE拥有多种编码方式，包括为UTF-8、UTF-16。（UCS Transfer Format，UCS是UNICDOE的简称）字符与字节不同的编码的字符串，其长度和大小怎么计算？字符串长度：字符串的实际长度，计算字符长度，strlen结果；字符串大小：字符串的空间占用大小，需要结合字符编码进行大小计算。MySQL下的字符编码show variables like ‘%character%’;                    character_set_client        客户端字符编码                    character_set_connection        网络传输数据的字符编码                    character_set_database        服务端数据字符编码                    character_set_filesystem        服务端文件名字符编码                    character_set_results        服务端返回结果集的字符编码                    character_set_server        服务端全局字符编码            MySQL字符集校对规则相同字符集内，字符比较和排序的规则。如果查看MySQL中，information_schema的CHARACTER_SETS，可以看到MySQL支持的字符集及其校对规则，例如：图中显示了MySQL支持的字符集，以及对应字符集的校对规则、字符集中字符的长度。其中，不同的校对规则，会以_ci、_cs、_bin结尾，分别代表了不同的比对模式，_ci为大小写不敏感，_cs为大小写敏感，_bin为二进制比对。MySQL表字符集修改修改表字符集（新数据生效）	ALTER TABLE  … CHARACTER SET …修改表字符集（新旧数据生效）	ALTER TABLE  … CONVERT TO CHARACTER SET …修改当前会话字符集	SET NAMES …（client、result、connection）]]></content>
      <categories>
        
          <category> Common </category>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> MySQL </tag>
        
          <tag> Character Coding </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[ElasticSearch分组相关性写入]]></title>
      <url>/elasticsearch/2018/05/25/elasticsearch-group-write/</url>
      <content type="text"><![CDATA[随着业务发展，越来越多的业务数据接入到Elasticsearch集群中，基于ES的全文索引和聚合分析功能进行简单的数据分析和日志查找。在设计之初出于数据量和数据隔离的考虑，每个产品都以日期进行划分，生成数据索引。但是，随着新的产品越来越多，单个产品按日期划分，导致集群中的索引数量不断增加，ES集群的写入速度也越来越慢。起初我们对原因进行分析，认为是数据索引过多导致数据节点写入过慢。于是，在每天晚上定时对最近三天的数据进行分析，找出哪些产品的数据量比较小，并将数据量较小的数据索引进行合并，以减少索引数量；同时每天定时关闭一周前的数据索引转为冷数据，以减轻集群负担，使ES集群的写入和查询速度均得到提升。在持续稳定了一段时间后，写入速度又开始下降，只有正常情况下写入峰值的一半左右，而此时的索引数量仍在可接受的范围内，于是猜测写入较慢和索引数量之间的没有直接影响的关系，可能是与写入时的数据相关性有关。在进行数据写入时，由于数据本身基于产品进行划分，短时间大量不同产品数据的写入，会导致ES在处理一次数据提交时，需要将数据写入不同的索引。基于以上推测，我进行了一次关于数据相关性分组写入的测试。测试主要对相同总量，不同分组的数据进行写入测试，结果如下：宿主机环境                    CPU        4核                    内存        8G            组件配置                    组件        版本                            Docker        1.12.6                    Centos        Linux version 3.10.0­514.26.2.el7.x86_6                    Elasticsearch        6.1            ES参数配置                    参数        值                            ES数据节点数        1                    索引分片数        5                    分片副本数        1                    thread_pool.index.queue_size        1000                    thread_pool.index.size        5            写入策略                    参数        值                            数据总条数        20000                    写入次数        100                    单次批量写入数据量        200            测试方式  在写入数据量配置相同的情况下，调整一次提交中数据写入的索引数，即把单次批量写入的200条数据，写入到不同的N个索引中进行测试测试结果                    数据总数        写入次数        单次写入数据条数        写入索引数N        总耗时(ms)        单次批量写入平均耗时(ms)        单词批量写入最大耗时(ms)                            20000        100        200        100        135895        1358        4301                    20000        100        200        50        128403        1284        3716                    20000        100        200        25        70075        700        1577                    20000        100        200        10        34501        345        1062                    20000        100        200        1        11326        113        724            结果分析  从结果中可以明显看出，单次批量写入的数据中，最终需要写入的索引数N越小，写入速度越快。由此可以得出，在提交进行写入的数据中，数据分组相关性越高，最终写入的索引数越少，写入会越快。后记  后来基于这次的测试结果，我对数据写入的逻辑进行调整，将数据进行分组后写入，以此来提高数据分组相关性。但是从最终测试结果来看，实际数据写入速度并没有太明显的提升。对原因进行分析后，发现原因如下：  之前对数据量较少的产品数据索引进行合并，部分不同产品的数据已经是写入到同一个合并后的索引。而在实际场景中，大部分产品的数据量都是很小的，绝大部分的产品数据都是写入到这个合并索引中，所以从另一个角度上减少了单次数据提交所需要写入的索引数，导致优化数据写入后的效果并不明显。]]></content>
      <categories>
        
          <category> ElasticSearch </category>
        
      </categories>
      <tags>
        
          <tag> ElasticSearch </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Java Jar包变更导致JVM崩溃问题]]></title>
      <url>/jvm/2018/04/02/jvm-crash-when-jar-modify/</url>
      <content type="text"><![CDATA[最近部分线上JAVA项目和Tomcat出现无规律性崩溃，崩溃信息主要为：异常（一）JException in thread "data_send_thread_1" java.lang.NoClassDefFoundError: com/****/StreamResetException        ...        at java.lang.ClassLoader.loadClass(ClassLoader.java:424)        at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331)        at java.lang.ClassLoader.loadClass(ClassLoader.java:357)        ... 10 more或者异常（二）Java frames: (J=compiled Java code, j=interpreted, Vv=VM code)J 128  java.util.zip.ZipFile.getEntry(J[BZ)J (0 bytes) @ 0x00007f62450db198 [0x00007f62450db140+0x58]J 103670 C2 sun.misc.URLClassPath$JarLoader.getResource(Ljava/lang/String;Z)Lsun/misc/Resource; (85 bytes)J 92261 C2 java.net.URLClassLoader$2.run()Ljava/lang/Object; (5 bytes) @ 0x00007f624b5aa3c0 [0x00007f624b5aa280+0x140]v  ~StubRoutines::call_stubJ 933  java.security.AccessController.doPrivileged(Ljava/security/PrivilegedAction;Ljava/security/AccessControlContext;)Ljava/lang/Object;J 107440 C2 java.net.URLClassLoader.findResource(Ljava/lang/String;)Ljava/net/URL; (37 bytes) @ 0x00007f624df35394 [0x00007f624df35300+0x94]J 107175 C2 java.lang.ClassLoader.getResource(Ljava/lang/String;)Ljava/net/URL; (36 bytes) @ 0x00007f6249f14f28 [0x00007f6249f14da0+0x188]J 107117 C2 org.apache.catalina.loader.WebappClassLoaderBase.getResourceAsStream(Ljava/lang/String;)Ljava/io/InputStream; (354 bytes)J 107084 C2 org.apache.catalina.startup.ContextConfig.checkHandlesTypes(Lorg/apache/tomcat/util/bcel/classfile/JavaClass;)V (462 bytes)可以看出，崩溃原因均可归结为Class加载失败导致的，而加载的这个Class是一个JAVA Agent中的一个类。异常（一）：线程进行类加载时抛出当对象创建时，ClassLoader会先判断对象对应的类是否已经加载过，如果没有，则会优先进行加载。但在当前场景下，ClassLoader进行类加载时，抛出了NoClassDefFoundError异常。其中，NoClassDefFoundError与ClassNotFoundException是有区别的。ClassNotFoundException是在进行动态类加载时出现，往往实现不知道这个类是否存在，比如调用Class.forName，通过反射进行类加载时容易出现这个异常；NoClassDefFoundError遇到的并不多，一般是在编译时明确该类存在，但是在运行时进行加载的时候，找不到该类的定义。异常（二）：Tomcat类加载时抛出Tomcat作为Web应用容器，为每一个Web应用创建一个单独的WebAppClassLoader，用于加载这个应用所需要的类，同时也以此将不同项目所需要的类隔离开来。从异常信息可以看出，当ClassLoader尝试去加载一个类时，首先进行Jar包扫描，找到对应的Class在哪个Jar报中，然后通过特殊的权限控制方式，读取Jar包进行类加载。而Jar包本身以Zip格式为基础，所以通过ZipFile获取文件入口，而此时抛出异常。异常分析 1.  NoClassDefFoundError为JVM运行时异常，是在尝试加载Class时无法找到抛出的； 2.  对Tomcat源码进行调试，发现在AppClassLoader中，包含宝对应Java Agent的JAR包路径，并在加载过程中检查该JAR包中是否包含对应的Class，相关代码如下：URLClassLoader.javaprotected Class&lt;?&gt; findClass(final String name)    throws ClassNotFoundException{    final Class&lt;?&gt; result;    try {        result = AccessController.doPrivileged(            new PrivilegedExceptionAction&lt;Class&lt;?&gt;&gt;() {                public Class&lt;?&gt; run() throws ClassNotFoundException {                    String path = name.replace('.', '/').concat(".class");                    Resource res = ucp.getResource(path, false);                    if (res != null) {                        try {                            return defineClass(name, res);                        } catch (IOException e) {                            throw new ClassNotFoundException(name, e);                        }                    } else {                        return null;                    }                }            }, acc);    } catch (java.security.PrivilegedActionException pae) {        throw (ClassNotFoundException) pae.getException();    }    if (result == null) {        throw new ClassNotFoundException(name);    }    return result;}其中，ucp.getResource(path, false)尝试对指定类的ClassPath进行加载，遍历当前ClassLoader所包含的所有JAR包资源，利用ZipFile的getEntry方法，从jar包中搜索对应的Class信息，相关代码如下：ZipFile.java/** * Returns the zip file entry for the specified name, or null * if not found. * * @param name the name of the entry * @return the zip file entry, or null if not found * @throws IllegalStateException if the zip file has been closed */public ZipEntry getEntry(String name) {    if (name == null) {        throw new NullPointerException("name");    }    long jzentry = 0;    synchronized (this) {        ensureOpen();        jzentry = getEntry(jzfile, zc.getBytes(name), true);        if (jzentry != 0) {            ZipEntry ze = getZipEntry(name, jzentry);            freeEntry(jzfile, jzentry);            return ze;        }    }    return null;}正常情况下在JAVA Agent的JAR包中搜索，能找到对应的Class信息，即getEntry方法返回非0；而出现异常时，getEntry方法返回0。 3.  使用strace查看getEntry时对应的系统调用，结果如下：（1）Class加载成功时，可以从对应的JAR包中读取到Class信息（2）Class加载异常时，无法读取到Class信息可以看到在对JAR包中Class进行加载时，找不到对应的Class。但是，实际上使用解压或者使用JD-GUI查看其内容时，是能够找到编译后的Class文件，所以该类是存在的。那么问题来了，为什么明明有却会说找不到？问题原因最终，根据错误的异常信息，在Java官网找到了相似的异常，其实这是JAVA本身就存在的一个问题：ID 1296729.1Java Virtual Machine (JVM) crashes in java.util.zip.ZipFile.getEntry() during Class Loading (文档 ID 1296729.1） -  Random crashes during classloading while a jar/zip file is being accessed.  Here is a typical stack trace. Please notice that a custom classloader calls java.util.zip.ZipFile.getEntry() and the crash happens somewhere in libzip or libc or a native windows dll：tack: [0xfffffffe4e900000,0xfffffffe4e940000], sp=0xfffffffe4e93b1a0, free space=236kNative frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)C [libc_psr.so.1+0xbf4]C [libzip.so+0xe280]C [libzip.so+0x28e8]C [libzip.so+0x2d9c]J java.util.zip.ZipFile.getEntry(JLjava/lang/String;Z)JJ java.util.zip.ZipFile.getEntry(Ljava/lang/String;)Ljava/util/zip/ZipEntry;J weblogic.utils.classloaders.JarClassFinder.getSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;J weblogic.utils.classloaders.AbstractClassFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;J weblogic.utils.classloaders.MultiClassFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;J weblogic.utils.classloaders.MultiClassFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;J weblogic.utils.classloaders.MultiClassFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;j weblogic.application.utils.CompositeWebAppFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;J weblogic.utils.classloaders.MultiClassFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;J weblogic.utils.classloaders.MultiClassFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;j weblogic.utils.classloaders.CodeGenClassFinder.getClassSource(Ljava/lang/String;)Lweblogic/utils/classloaders/Source;j weblogic.utils.classloaders.GenericClassLoader.findLocalClass(Ljava/lang/String;)Ljava/lang/Class;j weblogic.utils.classloaders.GenericClassLoader.findClass(Ljava/lang/String;)Ljava/lang/Class;j weblogic.utils.classloaders.ChangeAwareClassLoader.findClass(Ljava/lang/String;)Ljava/lang/Class;J java.lang.ClassLoader.loadClass(Ljava/lang/String;Z)Ljava/lang/Class;J weblogic.utils.classloaders.ChangeAwareClassLoader.loadClass(Ljava/lang/String;)Ljava/lang/Class;j java.lang.ClassLoader.loadClassInternal(Ljava/lang/String;)Ljava/lang/Class;其中，三种情况可能导致该问题发生：There are three possible scenarios here:1. While a class is in use it is dynamically reloaded from a jar file.2. While a jar file is being accessed by the class loader, the jar file is being modified.3. A Jarfile which was bigger than 4GB was accessed (applies to Java 6 and earlier only)Please note that a crash may happen even a long time after a jarfile was modified as classloaders keep references to jarfiles.Another possible sceanrio is when Java or the application itself is being patched while the application is running.而这次问题的发生是由于第二点引起的，我们在对JAVA Agent版本进行更新时，是使用覆盖源文件的方式进行，随着Tomcat或者JVM重启去重新加载新的Agent JAR包。在更新JAR包，由于JVM还是保持着原JAR包的引用，所以再尝试从JAR包中进行Class加载时抛出异常，导致JVM崩溃。其中有一点比较关键的是，即使在JAR包变更后很长一段时间，也会出现这个问题，原因是因为在正常情况下，业务主要流程已经都跑过一次，依赖的类已经加载过，所以很少触发新的类加载，而当应用走到某个很少触发的业务逻辑或者抛出某个未加载过的异常，需要从该变更过的JAR包中进行Class加载时，就会产生这个现象。解决方案1. StackOverFlow中有大佬表示可通过升级使用JAVA 9来解决，JDK9 early access builds已经解决该问题。（https://stackoverflow.com/questions/38326183/jvm-crashed-in-java-util-zip-zipfile-getentry）2. 启动时关闭MemoryMapping。JAVA Bug Fixs - 6929479（http://www.oracle.com/us/technologies/java/overview-156328.html）]]></content>
      <categories>
        
          <category> JVM </category>
        
      </categories>
      <tags>
        
          <tag> JVM </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[MySQL Communications link failure问题]]></title>
      <url>/common/2016/12/10/mysql-communications-link-failure/</url>
      <content type="text"><![CDATA[最近对项目进行测试，突然出现Communications link failure异常，原文如下：com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failureThe last packet successfully received from the server was 20,096 milliseconds ago.The last packet sent successfully to the server was 0 milliseconds ago.    at sun.reflect.GeneratedConstructorAccessor84.newInstance(Unknown Source) ~[?:?]    at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:1.7.0_75]    ...查看MySQL Status的Aborted_clients，变化如下：请求接口前：请求接口后：等待一段时间后：此时，再次请求接口，出现Communications link failure，可判断是MySQL认为连接已经无效，主动关闭了连接。查测试服务器MySQL相关配置后，发现wait_timeout设置为10s，再结合日志中last packet successfully received时间，判断可能为该配置问题。但是比较奇怪的是，线上项目正常。正常情况下，线上服务器应与测试服务器上的配置一致，保证测试结果有效。所以果断查看线上MySQL配置后，发现wait_timeout为600s，所以基本确定是因为测试服务器wait_timeout最近可能被人修改，导致出现这个MySQL主动关闭连接的情况。这又引出另一个问题，如果线上配置是600s，那么有过期连接后，MySQL依然会进行关闭，应该也会出现同样的错误，但是实际情况是线上项目一直正常，没有出现告警，于是怀疑是获取连接的时候，连接池进行了一些维护性工作。连接池使用的是阿里的DruidDataSource，查看连接其默认配置，发现：其中testOnBorrow和testOnReturn是默认不开启的，testWhileIdle默认为true，查看获取连接的相关代码，发现如下：if (isTestWhileIdle()) {    final long currentTimeMillis = System.currentTimeMillis();    final long lastActiveTimeMillis = poolableConnection.getConnectionHolder().getLastActiveTimeMillis();    final long idleMillis = currentTimeMillis - lastActiveTimeMillis;    long timeBetweenEvictionRunsMillis = this.getTimeBetweenEvictionRunsMillis();    if (timeBetweenEvictionRunsMillis &lt;= 0) {        timeBetweenEvictionRunsMillis = DEFAULT_TIME_BETWEEN_EVICTION_RUNS_MILLIS;    }    if (idleMillis &gt;= timeBetweenEvictionRunsMillis) {        boolean validate = testConnectionInternal(poolableConnection.getConnection());        if (!validate) {            if (LOG.isDebugEnabled()) {            LOG.debug("skip not validate connection.");            }            discardConnection(realConnection);                         continue;        }    }}其中，默认的DEFAULT_TIME_BETWEEN_EVICTION_RUNS_MILLIS为60s，即默认对超过60s的未活动连接进行检测，所以线上MySQL配置600s也没有出现Communications link failure。]]></content>
      <categories>
        
          <category> Common </category>
        
      </categories>
      <tags>
        
          <tag> MySQL </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
